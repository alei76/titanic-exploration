{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadhand/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xg\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pd.set_option('chained_assignment',None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv(\"../data/train.csv\")\n",
    "titanic_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1190</td>\n",
       "      <td>1</td>\n",
       "      <td>Loring, Mr. Joseph Holland</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113801</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1083</td>\n",
       "      <td>1</td>\n",
       "      <td>Salomon, Mr. Abraham L</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111163</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Mr. Albert Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "      <td>Canavan, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364858</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>953</td>\n",
       "      <td>2</td>\n",
       "      <td>McCrae, Mr. Arthur Gordon</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>237216</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1130</td>\n",
       "      <td>2</td>\n",
       "      <td>Hiltunen, Miss. Marta</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250650</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1020</td>\n",
       "      <td>2</td>\n",
       "      <td>Bowenur, Mr. Solomon</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211535</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1053</td>\n",
       "      <td>3</td>\n",
       "      <td>Touma, Master. Georges Youssef</td>\n",
       "      <td>male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2650</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "      <td>Frauenthal, Mr. Isaac Gerald</td>\n",
       "      <td>male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17765</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>D40</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1104</td>\n",
       "      <td>2</td>\n",
       "      <td>Deacon, Mr. Percy William</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1237</td>\n",
       "      <td>3</td>\n",
       "      <td>Abelseth, Miss. Karen Marie</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>348125</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1241</td>\n",
       "      <td>2</td>\n",
       "      <td>Walcroft, Miss. Nellie</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F.C.C. 13528</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1058</td>\n",
       "      <td>1</td>\n",
       "      <td>Brandeis, Mr. Emil</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17591</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>B10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1138</td>\n",
       "      <td>2</td>\n",
       "      <td>Karnes, Mrs. J Frank (Claire Bennett)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F.C.C. 13534</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1207</td>\n",
       "      <td>3</td>\n",
       "      <td>Hagardon, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AQ/3. 30631</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>Gibson, Miss. Dorothy Winifred</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112378</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1157</td>\n",
       "      <td>3</td>\n",
       "      <td>Lyntakoff, Mr. Stanko</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349235</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1220</td>\n",
       "      <td>2</td>\n",
       "      <td>Clarke, Mr. Charles Valentine</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1085</td>\n",
       "      <td>2</td>\n",
       "      <td>Lingane, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235509</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1033</td>\n",
       "      <td>1</td>\n",
       "      <td>Daniels, Miss. Sarah</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                   Name     Sex   Age  \\\n",
       "298         1190       1             Loring, Mr. Joseph Holland    male  30.0   \n",
       "191         1083       1                 Salomon, Mr. Abraham L    male   NaN   \n",
       "7            899       2           Caldwell, Mr. Albert Francis    male  26.0   \n",
       "388         1280       3                   Canavan, Mr. Patrick    male  21.0   \n",
       "61           953       2              McCrae, Mr. Arthur Gordon    male  32.0   \n",
       "238         1130       2                  Hiltunen, Miss. Marta  female  18.0   \n",
       "128         1020       2                   Bowenur, Mr. Solomon    male  42.0   \n",
       "161         1053       3         Touma, Master. Georges Youssef    male   7.0   \n",
       "404         1296       1           Frauenthal, Mr. Isaac Gerald    male  43.0   \n",
       "212         1104       2              Deacon, Mr. Percy William    male  17.0   \n",
       "345         1237       3            Abelseth, Miss. Karen Marie  female  16.0   \n",
       "349         1241       2                 Walcroft, Miss. Nellie  female  31.0   \n",
       "166         1058       1                     Brandeis, Mr. Emil    male  48.0   \n",
       "246         1138       2  Karnes, Mrs. J Frank (Claire Bennett)  female  22.0   \n",
       "315         1207       3                   Hagardon, Miss. Kate  female  17.0   \n",
       "402         1294       1         Gibson, Miss. Dorothy Winifred  female  22.0   \n",
       "265         1157       3                  Lyntakoff, Mr. Stanko    male   NaN   \n",
       "328         1220       2          Clarke, Mr. Charles Valentine    male  29.0   \n",
       "193         1085       2                      Lingane, Mr. John    male  61.0   \n",
       "141         1033       1                   Daniels, Miss. Sarah  female  33.0   \n",
       "\n",
       "     SibSp  Parch        Ticket      Fare Cabin Embarked  \n",
       "298      0      0        113801   45.5000   NaN        S  \n",
       "191      0      0        111163   26.0000   NaN        S  \n",
       "7        1      1        248738   29.0000   NaN        S  \n",
       "388      0      0        364858    7.7500   NaN        Q  \n",
       "61       0      0        237216   13.5000   NaN        S  \n",
       "238      1      1        250650   13.0000   NaN        S  \n",
       "128      0      0        211535   13.0000   NaN        S  \n",
       "161      1      1          2650   15.2458   NaN        C  \n",
       "404      1      0         17765   27.7208   D40        C  \n",
       "212      0      0  S.O.C. 14879   73.5000   NaN        S  \n",
       "345      0      0        348125    7.6500   NaN        S  \n",
       "349      0      0  F.C.C. 13528   21.0000   NaN        S  \n",
       "166      0      0      PC 17591   50.4958   B10        C  \n",
       "246      0      0  F.C.C. 13534   21.0000   NaN        S  \n",
       "315      0      0   AQ/3. 30631    7.7333   NaN        Q  \n",
       "402      0      1        112378   59.4000   NaN        C  \n",
       "265      0      0        349235    7.8958   NaN        S  \n",
       "328      1      0          2003   26.0000   NaN        S  \n",
       "193      0      0        235509   12.3500   NaN        Q  \n",
       "141      0      0        113781  151.5500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm taking out the names for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = titanic_train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin', 'Name']]\n",
    "y_train = titanic_train['Survived']\n",
    "\n",
    "X_test = titanic_test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin', 'Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cabin is a bit unwieldy. I'm going to just take the general area.\n",
    "# \"U\" means unknown\n",
    "\n",
    "X_train.loc[:, 'Cabin'].fillna('U', inplace = True)\n",
    "X_train.loc[:, 'Cabin'] = X_train.loc[:, 'Cabin'].apply(lambda n: n[0])\n",
    "\n",
    "X_test.loc[:, 'Cabin'].fillna('U', inplace = True)\n",
    "X_test.loc[:, 'Cabin'] = X_test.loc[:, 'Cabin'].apply(lambda n: n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are also missing values in Embarked\n",
    "\n",
    "X_train.loc[:, 'Embarked'].fillna('U', inplace = True)\n",
    "X_test.loc[:, 'Embarked'].fillna('U', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's also try to do something with names\n",
    "# X_train.loc[:, 'LastName'] = X_train.loc[:, \"Name\"].apply(lambda x: x.split(' ')[0])\n",
    "X_train.loc[:, 'Honorific'] = X_train.loc[:, \"Name\"].apply(lambda x: x.split(', ')[1].split(' ')[0])\n",
    "X_train.drop('Name', axis = 1, inplace = True)\n",
    "\n",
    "# X_test.loc[:, 'LastName'] = X_test.loc[:, \"Name\"].apply(lambda x: x.split(' ')[0])\n",
    "X_test.loc[:, 'Honorific'] = X_test.loc[:, \"Name\"].apply(lambda x: x.split(', ')[1].split(' ')[0])\n",
    "X_test.drop('Name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I tried to bin Age but wasn't able to find anything that improved cross-validation\n",
    "\n",
    "X_train_Age = pd.qcut(X_train.Age, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f172fe77be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f172fe04748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.DataFrame({'Age': X_train_Age,\n",
    "                         'Survived': y_train})\n",
    "\n",
    "sns.barplot(x=\"Age\", y=\"Survived\", data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories_to_encode = ['Embarked', 'Cabin', 'Sex', 'Honorific']\n",
    "\n",
    "# Need to temporarily merge in case of new labels in test\n",
    "X_combined = pd.concat([X_train[categories_to_encode], X_test[categories_to_encode]])\n",
    "\n",
    "for category in categories_to_encode:\n",
    "    labels = LabelEncoder()\n",
    "    labels.fit(X_combined[category])    \n",
    "    X_train[category] = labels.transform(X_train[category])\n",
    "    X_test[category] = labels.transform(X_test[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_imputer = Imputer(strategy='mean')\n",
    "X_train[['Age', 'Fare']] = mean_imputer.fit_transform(X_train[['Age', 'Fare']])\n",
    "X_test[['Age', 'Fare']] = mean_imputer.transform(X_test[['Age', 'Fare']])\n",
    "# Would use MICE, but I'm getting compiler errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This makes a big difference for SVC and KNN but not the others\n",
    "# RF and XGB are feature invariant and maybe RC is regularizing \n",
    "# the scaled features?\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[['Age', 'Fare']] = scaler.fit_transform(X_train[['Age', 'Fare']])\n",
    "X_test[['Age', 'Fare']] = scaler.transform(X_test[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Honorific</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.494412</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.053800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.386671</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.207709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896497</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.707912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.504962</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.208522</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.424256</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.336334</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.054207</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144885</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.361618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.489442</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491456</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792698</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.336334</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.163700</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.648422</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.490280</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502864</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  SibSp  Parch      Fare  Embarked  Cabin  Honorific\n",
       "544       1    1  1.562241      1      0  1.494412         0      2         12\n",
       "4         3    1  0.407926      0      0 -0.486337         2      8         12\n",
       "510       3    1 -0.053800      0      0 -0.492378         1      8         12\n",
       "387       2    0  0.484880      0      0 -0.386671         2      8          9\n",
       "681       1    1 -0.207709      0      0  0.896497         0      3         12\n",
       "767       3    0  0.061631      0      0 -0.492378         1      8          9\n",
       "227       3    1 -0.707912      0      0 -0.502445         2      8         12\n",
       "590       3    1  0.407926      0      0 -0.504962         2      8         12\n",
       "172       3    0 -2.208522      1      1 -0.424256         2      8          9\n",
       "657       3    0  0.177063      1      1 -0.336334         1      8         13\n",
       "853       1    0 -1.054207      0      1  0.144885         2      3          9\n",
       "794       3    1 -0.361618      0      0 -0.489442         2      8         12\n",
       "525       3    1  0.831175      0      0 -0.492378         1      8         12\n",
       "758       3    1  0.330972      0      0 -0.486337         2      8         12\n",
       "395       3    1 -0.592481      0      0 -0.491456         2      8         12\n",
       "188       3    1  0.792698      1      1 -0.336334         1      8         12\n",
       "412       1    0  0.254017      1      0  1.163700         1      2          9\n",
       "633       1    1  0.000000      0      0 -0.648422         2      8         12\n",
       "704       3    1 -0.284663      1      0 -0.490280         2      8         12\n",
       "57        3    1 -0.092277      0      0 -0.502864         0      8         12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X_train, X_test])\n",
    "dummy_combined = pd.get_dummies(X_combined, \n",
    "               columns = ['Pclass', 'Sex', 'Embarked', 'Cabin', 'Honorific'], \n",
    "               drop_first=True)\n",
    "\n",
    "X_train = dummy_combined.iloc[:X_train.shape[0], :]\n",
    "X_test = dummy_combined.iloc[X_train.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get a baseline with a few common models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "cross_val_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82834865509\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier()\n",
    "cvs = cross_val_score(ridge, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()\n",
    "print(cvs)\n",
    "cross_val_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836238508682\n"
     ]
    }
   ],
   "source": [
    "xgb = xg.XGBClassifier()\n",
    "cvs = cross_val_score(xgb, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()\n",
    "print(cvs)\n",
    "cross_val_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8204329815\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "cvs = cross_val_score(random_forest, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()\n",
    "print(cvs)\n",
    "cross_val_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833891442515\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "cvs = cross_val_score(svc, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()\n",
    "print(cvs)\n",
    "cross_val_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826062875951\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cvs = cross_val_score(knn, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()\n",
    "print(cvs)\n",
    "cross_val_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783465554421\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = BernoulliNB()\n",
    "cvs = cross_val_score(naive_bayes, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()\n",
    "print(cvs)\n",
    "cross_val_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809272216547\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "cvs = cross_val_score(mlp, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()\n",
    "print(cvs)\n",
    "cross_val_scores.append(cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Everything in a Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8395471569628874"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_cross_val_scores = cross_val_scores / sum(cross_val_scores)\n",
    "voter = VotingClassifier([('ridge', ridge), \n",
    "                          ('xgb', xgb),\n",
    "                          ('svc', svc),\n",
    "                          ('knn', knn),\n",
    "                          ('naive_bayes', naive_bayes),\n",
    "                          ('mlp', mlp),\n",
    "                          ('random_forest', random_forest)],\n",
    "                         weights = list(normed_cross_val_scores))\n",
    "cross_val_score(voter, X_train, y_train, scoring=accuracy_scorer, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadhand/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('ridge', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "        tol=0.001)), ('xgb', XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))],\n",
       "         n_jobs=1, voting='hard',\n",
       "         weights=[0.14436915293166208, 0.1457442399470715, 0.14298956586524389, 0.14533518036525878, 0.14397077478960654, 0.13654667964725339, 0.14104440645390395])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voter.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': titanic_test['PassengerId'],\n",
    "                          'Survived': voter.predict(X_test)})\n",
    "submission.to_csv('../results/voting_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This overfit massively. I'm also submitting my one best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xg_submission = pd.DataFrame({'PassengerId': titanic_test['PassengerId'],\n",
    "                          'Survived': xgb.predict(X_test)})\n",
    "submission.to_csv('../results/xgb_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Possible TODOs\n",
    "\n",
    "- Get MICE working for imputation\n",
    "- Hyperparameter optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
